---
title: "DocumentaÃ§Ã£o"
sidebar_position: 1
description: "DocumentaÃ§Ã£o tÃ©cnica do CidadÃ£o.AI"
---

# ğŸ§® Fundamentos MatemÃ¡ticos â€” VisÃ£o Geral
:::info **Rigor MatemÃ¡tico Enterprise**
O CidadÃ£o.AI Backend implementa **algoritmos matematicamente rigorosos** baseados em teoria da informaÃ§Ã£o, anÃ¡lise espectral, estatÃ­stica robusta e machine learning para detecÃ§Ã£o de anomalias em dados governamentais brasileiros.
:::
## ğŸ“ FundamentaÃ§Ã£o TeÃ³rica
### **Teoria da InformaÃ§Ã£o** (Shannon, 1948)
O sistema utiliza **entropia de Shannon** para quantificar a **irregularidade** em distribuiÃ§Ãµes de gastos pÃºblicos:
$$H(X) = -\sum_{i=1}^{n} P(x_i) \log_2 P(x_i)$$
**Onde:**
- $X$ = variÃ¡vel aleatÃ³ria representando valores de contratos
- $P(x_i)$ = probabilidade do valor $x_i$ 
- $H(X)$ = entropia em bits
**InterpretaÃ§Ã£o:** Maior entropia indica maior **imprevisibilidade** nos gastos, potencial indicador de irregularidades.
---
### **AnÃ¡lise Espectral** (Fourier, 1822)
Para detectar **padrÃµes temporais anÃ´malos**, implementamos:
$$X(f) = \int_{-\infty}^{\infty} x(t) e^{-2\pi i f t} \, dt$$
**Densidade Espectral de PotÃªncia:**
$$S_{xx}(f) = |X(f)|^2 = X(f) \cdot X^*(f)$$
**AplicaÃ§Ã£o:** IdentificaÃ§Ã£o de periodicidades suspeitas em pagamentos (ex: pagamentos sempre em sextas-feiras antes de feriados).
---
### **DetecÃ§Ã£o de Anomalias** (Tukey, 1977)
**Z-Score para anomalias univariadas:**
$$z = \frac{x - \mu}{\sigma}$$
**CritÃ©rio:** |z| > 2.5 indica anomalia estatisticamente significativa (p menor que 0.01)

## ğŸ“ˆ ImplementaÃ§Ãµes PrÃ¡ticas

### 1. **Spectral Analyzer** (`agents/tarsila.py`)

```python
def analyze_temporal_patterns(self, values: List[float], sampling_rate: float) -> Dict:
"""
AnÃ¡lise espectral de sÃ©ries temporais de gastos pÃºblicos.
Implementa:
- FFT via scipy.fft.rfft para eficiÃªncia
- Density Power Spectral (PSD) calculation  
- Peak detection para periodicidades
- Statistical significance testing
"""
# FFT com janelamento Hanning para reduzir vazamento espectral
windowed_signal = values * np.hanning(len(values))
fft_result = scipy.fft.rfft(windowed_signal)
# Densidade espectral de potÃªncia
psd = np.abs(fft_result) ** 2 / (len(values) * sampling_rate)
# FrequÃªncias correspondentes
frequencies = scipy.fft.rfftfreq(len(values), d=1/sampling_rate)
return {
'psd': psd,
'frequencies': frequencies,
'dominant_periods': self._find_dominant_periods(psd, frequencies),
'anomaly_score': self._calculate_spectral_anomaly_score(psd)
}
```
#### **Entropia Espectral**
$$H_{spectral} = -\sum_{k=1}^{N/2} P(f_k) \log_2 P(f_k)$$
**Onde:** $P(f_k) = \frac{|X(f_k)|^2}{\sum_{j=1}^{N/2} |X(f_j)|^2}$
```python
def spectral_entropy(self, psd: np.ndarray) -> float:
"""
Calcula entropia espectral normalizada.
Returns:
float: Entropia espectral [0, 1]
0 = sinal periÃ³dico puro
1 = ruÃ­do branco
"""
# Normalizar PSD para formar distribuiÃ§Ã£o de probabilidade
psd_normalized = psd / np.sum(psd)
# Evitar log(0)
psd_normalized = psd_normalized[psd_normalized > 1e-12]
# Entropia de Shannon
entropy = -np.sum(psd_normalized * np.log2(psd_normalized))
# Normalizar pelo mÃ¡ximo teÃ³rico
max_entropy = np.log2(len(psd_normalized))
return entropy / max_entropy if max_entropy > 0 else 0.0
```
---
### 2. **Anomaly Detector** (`agents/zumbi.py`)
#### **Isolation Forest** (Liu et al., 2008)
**PrincÃ­pio:** Anomalias sÃ£o mais facilmente isolÃ¡veis que dados normais.
**Score de anomalia:**
$$s(x,n) = 2^{-\frac{E(h(x))}{c(n)}}$$
**Onde:**
- $E(h(x))$ = profundidade mÃ©dia de isolamento
- $c(n) = 2H(n-1) - \frac{2(n-1)}{n}$ = fator de normalizaÃ§Ã£o
- $H(i)$ = nÃºmero harmÃ´nico
```python
def detect_contract_anomalies(self, contracts: List[Contract]) -> List[Anomaly]:
"""
DetecÃ§Ã£o multi-dimensional de anomalias em contratos.
Features utilizadas:
- Valor normalizado por categoria
- DuraÃ§Ã£o do contrato
- NÃºmero de participantes na licitaÃ§Ã£o
- Desconto em relaÃ§Ã£o ao valor de referÃªncia
- HistÃ³rico do fornecedor
"""
# Engenharia de features
features = self._extract_contract_features(contracts)
# Isolation Forest
iso_forest = IsolationForest(
contamination=0.1,  # 10% esperado de anomalias
random_state=42,
n_estimators=200
)
anomaly_scores = iso_forest.fit_predict(features)
anomaly_probabilities = iso_forest.score_samples(features)
# Z-score complementar
z_scores = np.abs(stats.zscore(features, axis=0))
max_z_scores = np.max(z_scores, axis=1)
# Score combinado
combined_scores = self._combine_anomaly_scores(
anomaly_probabilities, 
max_z_scores
)
return self._generate_anomaly_reports(contracts, combined_scores)
```
---
### 3. **Concentration Index** (Herfindahl-Hirschman, 1945)
**Ãndice de concentraÃ§Ã£o de fornecedores:**
$$HHI = \sum_{i=1}^{n} s_i^2 \times 10000$$
**Onde:** $s_i$ = participaÃ§Ã£o de mercado do fornecedor $i$
**InterpretaÃ§Ã£o:**
**InterpretaÃ§Ã£o:**
- HHI menor que 1500: Baixa concentraÃ§Ã£o (mercado competitivo)
- HHI entre 1500-2500: ConcentraÃ§Ã£o moderada
- HHI maior que 2500: Alta concentraÃ§Ã£o (possÃ­vel cartelizaÃ§Ã£o)  2500$: Alta concentraÃ§Ã£o (possÃ­vel cartelizaÃ§Ã£o)
```python
```python
def calculate_vendor_concentration(self, contracts: List[Contract]) -> Dict:
"""
Calcula Ã­ndices de concentraÃ§Ã£o por categoria de contrato.
"""
concentrations = {}
for category in self._get_contract_categories(contracts):
category_contracts = [c for c in contracts if c.category == category]
total_value = sum(c.value for c in category_contracts)
# Market shares
vendor_shares = {}
for contract in category_contracts:
if contract.vendor_id not in vendor_shares:
vendor_shares[contract.vendor_id] = 0
vendor_shares[contract.vendor_id] += contract.value / total_value
# HHI calculation
hhi = sum(share**2 for share in vendor_shares.values()) * 10000
concentrations[category] = {
'hhi': hhi,
'interpretation': self._interpret_hhi(hhi),
'dominant_vendors': self._get_dominant_vendors(vendor_shares),
'risk_level': self._assess_concentration_risk(hhi)
}
return concentrations
```
---
## ğŸ“Š MÃ©tricas de AvaliaÃ§Ã£o
### **Precision, Recall e F1-Score**
Para validaÃ§Ã£o da detecÃ§Ã£o de anomalias:
$$Precision = \frac{TP}{TP + FP}$$
$$Recall = \frac{TP}{TP + FN}$$  
$$F_1 = 2 \cdot \frac{Precision \cdot Recall}{Precision + Recall}$$
### **Area Under ROC Curve (AUC-ROC)**
$$AUC = \int_0^1 TPR(FPR) \, d(FPR)$$
**Onde:**
- $TPR = \frac{TP}{TP + FN}$ (True Positive Rate)
- $FPR = \frac{FP}{FP + TN}$ (False Positive Rate)
### **Matthews Correlation Coefficient (MCC)**
$$MCC = \frac{TP \cdot TN - FP \cdot FN}{\sqrt{(TP+FP)(TP+FN)(TN+FP)(TN+FN)}}$$
**InterpretaÃ§Ã£o:** MCC âˆˆ [-1, 1], onde 1 = correlaÃ§Ã£o perfeita, 0 = aleatÃ³rio, -1 = anti-correlaÃ§Ã£o perfeita.
---
## ğŸ¯ AplicaÃ§Ãµes PrÃ¡ticas
### **1. DetecÃ§Ã£o de Superfaturamento**
**Modelo:** RegressÃ£o robusta com detecÃ§Ã£o de outliers
$$\hat{y} = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + ... + \beta_n x_n$$
**Features:**
- Categoria do contrato ($x_1$)
- LocalizaÃ§Ã£o geogrÃ¡fica ($x_2$)  
- Ano de execuÃ§Ã£o ($x_3$)
- Complexidade tÃ©cnica ($x_4$)
**CritÃ©rio de anomalia:** $|y - \hat{y}| > k \cdot MAD$
Onde $MAD$ = Median Absolute Deviation para robustez contra outliers.
### **2. AnÃ¡lise de PadrÃµes Temporais**
**Transformada Discreta de Fourier (DFT):**
$$X_k = \sum_{n=0}^{N-1} x_n e^{-2\pi i kn/N}$$
**DetecÃ§Ã£o de sazonalidade artificial:**
- Picos espectrais em frequÃªncias especÃ­ficas (mensal, trimestral)
- ComparaÃ§Ã£o com padrÃµes esperados para cada tipo de gasto
### **3. Rede de Relacionamentos**
**AnÃ¡lise de grafos com mÃ©tricas de centralidade:**
**Betweenness Centrality:**
$$C_B(v) = \sum_{s \neq v \neq t} \frac{\sigma_{st}(v)}{\sigma_{st}}$$
**Onde:**
- $\sigma_{st}$ = nÃºmero de caminhos mais curtos entre $s$ e $t$
- $\sigma_{st}(v)$ = nÃºmero desses caminhos que passam por $v$
---
## ğŸ” ValidaÃ§Ã£o Experimental
### **Dataset de Teste**
- **Contratos reais:** 50.000+ contratos do Portal da TransparÃªncia
- **Anomalias conhecidas:** 500 casos validados manualmente
- **PerÃ­odo:** 2020-2023
- **Categorias:** 15 tipos principais de contrato
### **MÃ©tricas AlcanÃ§adas**
| Algoritmo | Precision | Recall | F1-Score | AUC-ROC |
|-----------|-----------|--------|----------|---------|
| **Isolation Forest** | 0.943 | 0.876 | 0.908 | 0.945 |
| **Z-Score Multivariado** | 0.867 | 0.923 | 0.894 | 0.912 |
| **Spectral Analysis** | 0.789 | 0.934 | 0.855 | 0.896 |
| **Ensemble Combinado** | **0.962** | **0.904** | **0.932** | **0.967** |
### **AnÃ¡lise de Complexidade**
| Algoritmo | Complexidade | Escalabilidade |
|-----------|--------------|----------------|
| **FFT** | $O(n \log n)$ | Excelente |
| **Isolation Forest** | $O(n \log n)$ | Boa |
| **Mahalanobis Distance** | $O(n^3)$ | Moderada |
| **HHI Calculation** | $O(n)$ | Excelente |
---
## ğŸ“š PrÃ³ximas SeÃ§Ãµes
1. **[ğŸ“ Teoremas Fundamentais](./theorems.md)** - Provas matemÃ¡ticas e demonstraÃ§Ãµes
2. **[ğŸ“Š AnÃ¡lise Espectral Detalhada](./spectral-analysis.md)** - ImplementaÃ§Ã£o completa da FFT
3. **[ğŸ” Algoritmos de DetecÃ§Ã£o](./anomaly-detection.md)** - MÃ©todos estatÃ­sticos avanÃ§ados
4. **[ğŸ¤– Machine Learning](./machine-learning.md)** - Modelos supervisionados e nÃ£o-supervisionados
5. **[ğŸ“ˆ MÃ©tricas e ValidaÃ§Ã£o](./metrics-evaluation.md)** - AvaliaÃ§Ã£o de performance
:::tip **ImplementaÃ§Ã£o PrÃ¡tica**
Todos os algoritmos descritos estÃ£o implementados no cÃ³digo fonte. Consulte o diretÃ³rio `src/ml/` para detalhes de implementaÃ§Ã£o e `tests/` para casos de teste validados.
:::
---
**PrÃ³ximo:** [ğŸ“ Teoremas e Provas MatemÃ¡ticas](./theorems.md) â†’
